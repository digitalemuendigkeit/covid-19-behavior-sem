---
title: "Climate Crisis Iteration 1 Measurement Model Evaluation"
output: html_document
---

```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Include libraries
library(tidyverse)
library(seminr)
library(DT)
library(htmltools)
# Load models and create summaries
model <- readRDS("Models/model-cc-1.RDS")
bootmodel <- readRDS("Models/model-boot-cc-1.RDS")
bootfsmodel <- readRDS("Models/model-fs-boot-cc-1.RDS")
summo <- summary(model)
summo$fSquare
sumfs <- summary(model$first_stage_model)
sumbomo <- summary(bootmodel)
sumbofsmo <- summary(bootfsmodel)
# Load redundancy analysis models
rapse <- readRDS("Models/rapse-cc-1.RDS")
rapre <- readRDS("Models/rapre-cc-1.RDS")
raprc <- readRDS("Models/raprc-cc-1.RDS")
radn <- readRDS("Models/radn-cc-1.RDS")
rain <- readRDS("Models/rain-cc-1.RDS")
rabi <- readRDS("Models/rabi-cc-1.RDS")
# Set seminr plot theme
thm <- seminr_theme_create(construct.compositeA.arrow = "backward", construct.compositeA.use_weights = FALSE, plot.adj = FALSE)
seminr_theme_set(thm)
```

# Model plots
## Original Estimate Path Model
This is the original estimate path model.
```{r plot model, echo=FALSE, out.width="100%"}
plot(model, title = "Original Estimate Model")
```

## Bootstrapped Path Model
This is the bootstrapped path model.
```{r plot bootmodel, echo=FALSE}
plot(bootmodel, title = "Bootstrapped Model")
```

## Measurement Model Only
This is a path model showing only the measurement model components.
```{r plot mm model, echo=FALSE}
plot(bootmodel, measurement_only = TRUE)
```
```{r eval-df, echo = FALSE, include=FALSE}
# Base DF
evalmm <- data.frame(Construct = model$mmMatrix[,1],
                           Type = ifelse(grepl("HOCB", model$mmMatrix[,3]),
                                         "HOC", "Construct"),
                           Mode = dplyr::recode(model$mmMatrix[,3],
                                         "A" = "reflective",
                                         "B" = "formative",
                                         "HOCB" = "higher-order"),
                           Indicator.or.LOC = model$mmMatrix[,2])
```

# Evaluation of the reflective measurement model
```{r ref-eval prep, echo = FALSE, include=FALSE}
refevalmmbase <- evalmm %>% filter(Mode == "reflective") %>% rename(Indicator = Indicator.or.LOC) %>% 
  mutate(Type = NULL, Mode = NULL)
refloadings <- c()
for (i in 1:nrow(refevalmmbase)){
  refloadings <<- append(refloadings, sumfs$loadings[refevalmmbase$Indicator[i], refevalmmbase$Construct[i]])
}

cicr <- data.frame(Construct = row.names(sumfs$reliability), 
                   AVE = as.numeric(sumfs$reliability[,3]), 
                   Calpha = as.numeric(sumfs$reliability[,1]),
                   rhoC = as.numeric(sumfs$reliability[,2]),
                   rhoA = as.numeric(sumfs$reliability[,4]))
#Next step is HTMT
boothtmtbase <- data.frame(Construct.Rel. = row.names(sumbomo$bootstrapped_HTMT),
                          Lower.CI = as.numeric(sumbomo$bootstrapped_HTMT[,5]),
                          Upper.CI = as.numeric(sumbomo$bootstrapped_HTMT[,6])) %>%
  rbind(data.frame(Construct.Rel. = row.names(sumbofsmo$bootstrapped_HTMT),
                          Lower.CI = as.numeric(sumbofsmo$bootstrapped_HTMT[,5]),
                          Upper.CI = as.numeric(sumbofsmo$bootstrapped_HTMT[,6])))
#For HTMT evaluation, one should consider only reflective constructs and LOCs
htmtvec <- c(unique(refevalmmbase$Construct))
# Transform "Relationships" Column into two distinct columns
boothtmtsplit <- base::strsplit(boothtmtbase$Construct.Rel., "  ->  ")
boothtmtsplit1 <- c()
boothtmtsplit2 <- c()
for (i in 1:length(boothtmtsplit)){
 boothtmtsplit1 <<- append(boothtmtsplit1, boothtmtsplit[[i]][1])
 boothtmtsplit2 <<- append(boothtmtsplit2, boothtmtsplit[[i]][2])
}
boothtmt <- (boothtmtbase %>% mutate(Construct.Rel. = NULL, Construct.1 = boothtmtsplit1, Construct.2 = boothtmtsplit2))[,c(3:4,1:2)] %>%
  filter(Construct.1 %in% htmtvec & Construct.2 %in% htmtvec)
maxhtmt <- data.frame(Construct = boothtmt[,1], Max.HTMT =  boothtmt[,4]) %>% 
  rbind(data.frame(Construct = boothtmt[,2], Max.HTMT =  boothtmt[,4])) %>%
  group_by(Construct) %>%
  summarise(Max.HTMT = max(Max.HTMT)) %>%
  mutate('1.in.HTMT.CI' = ifelse(Max.HTMT >=1, TRUE, FALSE))
# Make final data frame
refevalmm <- refevalmmbase %>% cbind(Loadings = refloadings) %>% left_join(cicr) %>% left_join(maxhtmt[,c(1,3)])
```

## Convergent validity
Ideally, outer loadings (<font face="Symbol">l</font>) should be $\geq$ 0.70. Loadings below 0.40 are unacceptable. AVE should be > 0.50. 

## Internal consistency reliability
Cronbach's <font face="Symbol">a</font>, composite reliability <font face="Symbol">r</font><sub>c</sub> and construct reliability <font face="Symbol">r</font><sub>A</sub> should be $\geq$ 0.60 and $\leq$ 0.90. The upper threshold of acceptability is 0.95.

## Discriminant validity
Discriminant validity is evaluated using the heterotrait-monotrait ratio (HTMT). The HTMT bootstrap confidence interval should not contain 1.

```{r ref-eval, echo=FALSE}
datatable(refevalmm,
          filter = 'top',
          options = list(pageLength = nrow(refevalmm)),
          rownames = FALSE,
          colnames = c("Loading" = 3,
                        "Cronbach\'s alpha" = 5, 
                       "Composite reliability" = 6,
                       "Construct reliability" = 7,
                       "1 in HTMT CI" = 8),
          caption = 'Results of the reflective measurement model evaluation') %>%
  formatRound(3:7,
              digits = 3) %>%
  formatStyle('Loading', backgroundColor = styleInterval(cuts = c(0.4, 0.708), values = c('#ff9999', '#ffe5e5', '#00'))) %>%
  formatStyle('AVE', backgroundColor = styleInterval(cuts = c(0.5), values = c('#ff9999', '#00'))) %>%
  formatStyle('Cronbach\'s alpha', backgroundColor = styleInterval(cuts = c(0.6,0.9,0.95,0.999), values = c('#ff9999', '#00','#ffe5e5',  '#ff9999', '#00'))) %>%
  formatStyle('Composite reliability', backgroundColor = styleInterval(cuts = c(0.6,0.9,0.95,0.999), values = c('#ff9999', '#00', '#ffe5e5', '#ff9999', '#00'))) %>%
    formatStyle('Construct reliability', backgroundColor = styleInterval(cuts = c(0.6,0.9,0.95,0.999), values = c('#ff9999', '#00','#ffe5e5',  '#ff9999', '#00'))) %>%
  formatStyle('1 in HTMT CI', backgroundColor = styleEqual(c(1,0), c('#ff9999', '#00'), default = NULL))
```
Convergent Validity is established for all constructs. 
Internal consistency reliability is established for all constructs as well, but for Personal Moral Norm, all three indices are above the 0.9 threshold. 
Concerning discriminant validity, all three distrusting beliefs lower-order constructs have 1 in the HTMT confidence interval. 
Other than that, there are no problems with discriminant validity as indicated by the HTMT ratio. 

```{r ref-eval-HTMT,echo=FALSE}
#If there are problems with the HTMT, here is a detailed table
datatable(boothtmt,
          filter = 'top',
          options = list(pageLength = nrow(boothtmt)),
          rownames = FALSE,
          colnames = c("Construct 1" = 1,
                        "Construct 2" = 2, 
                       "Lower CI HTMT" = 3, 
                       "Upper CI HTMT" = 4),
          caption = 'Details of the bootstrapped HTMT ratios') %>%
  formatRound(3:4,
              digits = 3) %>%
  formatStyle('Lower CI HTMT', backgroundColor = styleInterval(cuts = c(0.9,1), values = c('#00', '#ffe5e5', '#ff9999'))) %>%
  formatStyle('Upper CI HTMT', backgroundColor = styleInterval(cuts = c(0.9,1), values = c('#00', '#ffe5e5', '#ff9999')))
```
Looking at the HTMT bootstrap confidence intervals, it becomes apparent that there is overlap between the Distrusting Beliefs lower-order constructs Competence and Integrity, Benevolence and Integrity, and Benevolence and Competence. 
As these are lower-order constructs of the same higher-order construct, this does not pose a problem.
Additionally, the CIs for Perceived Susceptibility and Perceived Severity, as well as for Personal Moral Norm and Perceived Severity contain 0.9. 
For Perceived Susceptibility and Perceived Severity, this does again not pose a problem as they are LOCs associated with the same HOC. 
For Personal Moral Norm and Perceived Severity, however, further indicator deletion in order to rectify discriminant validity could raise the HTMT bootstrap ratio.

```{r indicator deletion personal norm, echo = FALSE, include = FALSE}
as.data.frame(unlist(summo$descriptives$correlations$items)) %>% select(starts_with("CCPN")) %>% rownames_to_column %>% filter(str_detect(rowname, "CCPN"))
```

## Results of the evaluation of the reflective measurement model
All indicators show sufficient convergent validity, internal consistency reliability and discriminant validity. 
All HTMT CI upper bounds above 1 are associated with LOCs and do not pose a problem. 
For Personal Moral Norm, the internal consistency reliability indices are all above 0.9, but below 0.95. 
Deletion of one of the indicators could lower these values. 
Because the HTMT bootstrap CI of Personal Norm with Perceived Severity contains 0.9 already, further indicator deletion could lead to the HTMT ration reaching critical values. 
Therefore, for the next iteration CCPN2, the indicator with the strongest intercorrelation, will be deleted.
However, if this leads to problems with the HTMT ratio, it should be taken back into the model. 
Otherwise, the hypothesized reflective measurement model and all its indicators can be retained.

# Evaluation of the formative measurement model
```{r for-eval prep, echo = FALSE, include=FALSE}
forevalbase <- evalmm %>% filter(Mode == "formative") %>% rename(Indicator = Indicator.or.LOC) %>% 
  mutate(Type = NULL, Mode = NULL)
```
## Convergent validity
To evaluate convergent validity, a redundancy analysis is conducted. The path coefficient should be $\geq$ 0.70 and RÂ² should be $\geq$ 0.50.

```{r for-eval rapse, echo=FALSE}
# Unfortunately, this has to be done partially manually
# Copy this snippet for as many formative constructs as you want to evaluate and alter it to your needs
plot(rapse, title = "Redundancy Analysis Perceived Self-Efficacy")
sumrapse <- summary(rapse)
# For the final dataframe, you should set a custom name and put the the name of the construct
cvpse <- data.frame(Construct = "Perceived Self-Efficacy", 'C.V.R^2' = sumrapse$paths[1], 'C.V.PC' = sumrapse$paths[3])
```

```{r for-eval rapre, echo=FALSE}
# Unfortunately, this has to be done partially manually
# Copy this snippet for as many formative constructs as you want to evaluate and alter it to your needs
plot(rapre, title = "Redundancy Analysis Perceived Response Efficacy")
sumrapre <- summary(rapre)
# For the final dataframe, you should set a custom name and put the the name of the construct
cvpre <- data.frame(Construct = "Perceived Response Efficacy", 'C.V.R^2' = sumrapre$paths[1], 'C.V.PC' = sumrapre$paths[3])
```

```{r for-eval raprc, echo=FALSE}
# Unfortunately, this has to be done partially manually
# Copy this snippet for as many formative constructs as you want to evaluate and alter it to your needs
plot(raprc, title = "Redundancy Analysis Perceived Response Costs")
sumraprc <- summary(raprc)
# For the final dataframe, you should set a custom name and put the the name of the construct
cvprc <- data.frame(Construct = "Perceived Response Costs", 'C.V.R^2' = sumraprc$paths[1], 'C.V.PC' = sumraprc$paths[3])
```

```{r for-eval radn, echo=FALSE}
# Unfortunately, this has to be done partially manually
# Copy this snippet for as many formative constructs as you want to evaluate and alter it to your needs
plot(radn, title = "Redundancy Analysis Descriptive Norm")
sumradn <- summary(radn)
# For the final dataframe, you should set a custom name and put the the name of the construct
cvdn <- data.frame(Construct = "Descriptive Norm", 'C.V.R^2' = sumradn$paths[1], 'C.V.PC' = sumradn$paths[3])
```

```{r for-eval rain, echo=FALSE}
# Unfortunately, this has to be done partially manually
# Copy this snippet for as many formative constructs as you want to evaluate and alter it to your needs
plot(rain, title = "Redundancy Analysis Injunctive Norm")
sumrain <- summary(rain)
# For the final dataframe, you should set a custom name and put the the name of the construct
cvin <- data.frame(Construct = "Injunctive Norm", 'C.V.R^2' = sumrain$paths[1], 'C.V.PC' = sumrain$paths[3])
```

```{r for-eval rabi, echo=FALSE}
# Unfortunately, this has to be done partially manually
# Copy this snippet for as many formative constructs as you want to evaluate and alter it to your needs
plot(rabi, title = "Redundancy Analysis Behavioral Intention")
sumrabi <- summary(rabi)
# For the final dataframe, you should set a custom name and put the the name of the construct
cvbi <- data.frame(Construct = "Behavioral Intention", 'C.V.R^2' = sumrabi$paths[1], 'C.V.PC' = sumrabi$paths[3])
```
```{r for-eval cv,echo=FALSE, include=FALSE}
# put together all dataframes, this has also to be done manually
forevalci <- bind_rows(cvpse, cvpre, cvprc, cvdn, cvin, cvbi)
```

Reiterating: For sufficient convergent validity, the path coefficient should be $\geq$ 0.70 and RÂ² should be $\geq$ 0.50.

## Collinearity
The variance inflation factor (VIF) should be < 5, ideally $\leq$ 3.

```{r for-eval col, echo = FALSE, include = FALSE}
mmvif <- data.frame(Construct = character(),
                      Indicator = character(),
                      VIF = double())
for (i in 1:length(unique(forevalbase$Construct))){
  for (j in 1:nrow(filter(forevalbase, Construct == unique(forevalbase$Construct)[i]))){
    x = unique(forevalbase$Construct)[i]
    y = (filter(forevalbase, Construct == x))[j,"Indicator"]
    mmvif <- mmvif %>% rbind(data.frame(Construct = x,
                              Indicator = y,
                              VIF = unlist(sumfs$validity$vif_items)[paste0({{x}}, ".", {{y}})]))
  }}
```

## Significance and relevance
Indicator weights should be significant (t \$geq$ 1.65, bootstrapping CI does not include 0). Otherwise, the loading  <font face="Symbol">l</font> should be $\geq$ 0.50 and significant. Any positive indicator weight implies relevance.

```{r for-eval sar, echo=FALSE, include=FALSE}
# Make weights df
btwtbase <- rownames_to_column(as.data.frame(sumbomo$bootstrapped_weights)) %>% rename (
  Construct.Rel. = rowname,
  Original.Est.Wt. = "Original Est.",
  Bootstrap.Mean.Wt. = "Bootstrap Mean",
  Bootstrap.SD.Wt. = "Bootstrap SD",
  T.Stat.Wt. = "T Stat.",
  Lower.Bounds.CI.Wt. = "2.5% CI",
  Upper.Bounds.CI.Wt. = "97.5% CI"
)
btwtsplit <- base::strsplit(btwtbase$Construct.Rel., "  ->  ")
btwtsplit1 <- c()
btwtsplit2 <- c()
for (i in 1:length(btwtsplit)){
  btwtsplit1 <- append(btwtsplit1, btwtsplit[[i]][1])
  btwtsplit2 <- append(btwtsplit2, btwtsplit[[i]][2])
}
btwt <- btwtbase %>%
  cbind(data.frame(Indicator = btwtsplit1, Construct = btwtsplit2)) %>%
  mutate(Construct.Rel. = NULL,
         Bootstrap.SD.Wt. = NULL,
         '0.in.Wt.CI' = ifelse(Lower.Bounds.CI.Wt. < 0 &  Upper.Bounds.CI.Wt. > 0, TRUE, FALSE),
         Lower.Bounds.CI.Wt. = NULL,
         Upper.Bounds.CI.Wt. = NULL)
# Make loadings df
btldbase <- rownames_to_column(as.data.frame(sumbomo$bootstrapped_loadings)) %>% rename(
  Construct.Rel. = rowname,
  Original.Est.Ld. = "Original Est.",
  Bootstrap.Mean.Ld. = "Bootstrap Mean",
  Bootstrap.SD.Ld. = "Bootstrap SD",
  T.Stat.Ld. = "T Stat.",
  Lower.Bounds.CI.Ld. = "2.5% CI",
  Upper.Bounds.CI.Ld. = "97.5% CI"
)
btldsplit <- base::strsplit(btldbase$Construct.Rel., "  ->  ")
btldsplit1 <- c()
btldsplit2 <- c()
for (i in 1:length(btldsplit)){
  btldsplit1 <- append(btldsplit1, btldsplit[[i]][1])
  btldsplit2 <- append(btldsplit1, btldsplit[[i]][2])
}
btld <- btldbase %>%
  cbind(data.frame(Indicator = btldsplit1, Construct = btldsplit1)) %>%
  mutate(Construct.Rel. = NULL,
         Bootstrap.SD.Ld. = NULL,
         '0.in.Ld.CI' = ifelse(Lower.Bounds.CI.Ld. < 0 &  Upper.Bounds.CI.Ld. > 0, TRUE, FALSE),
         Lower.Bounds.CI.Ld. = NULL,
         Upper.Bounds.CI.Ld. = NULL)

#Make final data frame
forevalmm <- forevalbase %>% 
  left_join(forevalci) %>%
  left_join(mmvif[,2:3]) %>%
  left_join(btwt[,-5]) %>%
  left_join(btld[,-5])
colnames(forevalmm)[8] <- paste0("t(", nrow(model$data), ") (weight)")
colnames(forevalmm)[12] <- paste0("t(", nrow(model$data), ") (loading)")
```

```{r for-eval, echo=FALSE}
datatable(forevalmm,
          filter = 'top',
          options = list(pageLength = nrow(forevalmm)),
          rownames = FALSE,
          colnames = c("CV R^2" = 3,
                        "CV pc" = 4, 
                       "Weight (original estimate)" = 6, 
                       "Weight (bootstrap mean)" = 7,
                       "0 in CI (weight)" = 9,
                       "Loading (original estimate)" = 10,
                       "Loading (bootstrap mean)" = 11,
                       "0 in CI (loading)" = 13),
          caption = 'Results of the formative measurement model evaluation') %>%
  formatRound(c(3:8, 10:12),
              digits = 3) %>%
  formatStyle('CV R^2', backgroundColor = styleInterval(cuts = c(0.5), values = c('#ff9999', '#00'))) %>%
  formatStyle('CV pc', backgroundColor = styleInterval(cuts = c(0.7), values = c('#ff9999', '#00'))) %>%
  formatStyle('VIF', backgroundColor = styleInterval(cuts = c(3,5), values = c('#00', '#ffe5e5','#ff9999'))) %>%
  formatStyle(colnames(forevalmm)[8], backgroundColor = styleInterval(cuts = c(1.65), values = c('#ffe5e5', '#00'))) %>%
  formatStyle('Loading (original estimate)', backgroundColor = styleInterval(cuts = c(0.5), values = c('#ff9999', '#00'))) %>%
  formatStyle('Loading (bootstrap mean)', backgroundColor = styleInterval(cuts = c(0.5), values = c('#ff9999', '#00'))) %>%
  formatStyle(colnames(forevalmm)[12], backgroundColor = styleInterval(cuts = c(1.65), values = c('#ff9999', '#00'))) %>%
  formatStyle('0 in CI (weight)', backgroundColor = styleEqual(c(1,0), c('#ffe5e5', '#00'), default = NULL)) %>%
  formatStyle('0 in CI (loading)', backgroundColor = styleEqual(c(1,0), c('#ff9999', '#00'), default = NULL))
```

Convergent validity is insufficient for Perceived Self-Efficacy, Perceived Response Efficacy, Perceived Response Costs and Behavioral Intention.
There are no issues with collinearity as indicated by the VIF.
Concerning significance and relevance, the weight for CCRB8 is very small and non-significant, and the loading is below 0.5. 
Therefore, CCRB8 should be discarded.
For CCIN1, the weight is also insignificant (0 in the bootstrapping CI), but the loading is large and significant.
Therefore, CCIN1 can be retained.
To remedy the problems with convergent validity, we look at the correlations of the indicators with the redundant reflective measure.
Possibly, indicator deletion can lead to stronger correlation of the formative construct with the reflective construct.

```{r modified ra pse, echo = FALSE, include=FALSE}
unlist(sumrapse$descriptives$correlations$items)[rapse$mmMatrix[4,2],rapse$mmMatrix[1:3,2]]
rapsem <- estimate_pls(model$data,
             measurement_model = constructs(
               composite("Perceived Self-Efficacy Formative", multi_items("CCRB", 1:2), mode_B),
               composite("Perceived Self-Efficacy Reflective", single_item("CCRB10"))),
             structural_model = relationships(
                paths(from = "Perceived Self-Efficacy Formative", to = "Perceived Self-Efficacy Reflective")))
```
```{r modiefied ra pse plot, echo=FALSE}
plot(rapsem, title = "Redundancy Analysis Perceived Self-Efficacy Modified")
```

For Perceived Self-Efficacy, all correlations of the formative measures with the reflective measure are below 0.5, with CCRB3 showing the lowest correlation with the reflective measure.
However, deletion of CCRB3 does not lead to sufficient convergent validity.

```{r modified ra pre, echo = FALSE ,include=FALSE}
unlist(sumrapre$descriptives$correlations$items)[rapre$mmMatrix[4,2],rapre$mmMatrix[1:3,2]]
raprem <- estimate_pls(model$data,
             measurement_model = constructs(
               composite("Perceived Response Efficacy Formative", multi_items("CCRB", 4:5), mode_B),
               composite("Perceived Response Efficacy Reflective", single_item("CCRB11"))),
             structural_model = relationships(
                paths(from = "Perceived Response Efficacy Formative", to = "Perceived Response Efficacy Reflective")))
```
```{r modified ra pre plot, echo=FALSE}
plot(raprem, title = "Redundancy Analysis Perceived Response Efficacy Modified")
```
For Perceived Response Efficacy, all correlations of the formative measures with the reflective measures are around 0.5.
CCRB6 shows the lower correlation.
Again, indicator deletion does not lead to sufficient convergent validity.

```{r modified ra prc, echo = FALSE, include =FALSE}
unlist(sumraprc$descriptives$correlations$items)[raprc$mmMatrix[4,2],raprc$mmMatrix[1:3,2]]
raprcm <- estimate_pls(model$data,
             measurement_model = constructs(
               composite("Perceived Response Costs Formative", multi_items("CCRB", c(7,9)), mode_B),
               composite("Perceived Response Costs Reflective", single_item("CCRB12"))),
             structural_model = relationships(
                paths(from = "Perceived Response Costs Formative", to = "Perceived Response Costs Reflective")))
```
```{r modified ra prc plot, echo=FALSE}
plot(raprcm, title = "Redundancy Analysis Perceived Response Costs Modified")
```
Here, correlations are around 0.4, with CCRB8 showing the lowest correlation.
As expected, indicator deletion does not lead to convergent validity.

```{r modified ra bi, echo = FALSE, include = FALSE}
unlist(sumrabi$descriptives$correlations$items)[rabi$mmMatrix[4,2],rabi$mmMatrix[1:3,2]]
rabim <- estimate_pls(model$data,
             measurement_model = constructs(
               composite("Behavioral Intention Formative", multi_items("CCBI", 2:3), mode_B),
               composite("Behavioral Intention Reflective", single_item("CCBI4"))),
             structural_model = relationships(
                paths(from = "Behavioral Intention Formative", to = "Behavioral Intention Reflective")))
```
```{r modified ra bi plot, echo=FALSE}
plot(rabim, title = "Redundancy Analysis Behavioral Intention Modified")
```
The lowest correlation is for CCBI1, the others are just below 0.5.
Indicator deletion does not lead to convergent validity.

## Results of the evaluation of the formative measurement model
Convergent validity cannot be established for any of the Response Beliefs lower-order constructs, or for Behavioral Intention.
Consequently, four distinct models should be estimated for each of the behaviors (formative: diet, driving, heating, and redundant reflective: general behavior).
There is no collinearity as indicated by the VIF.
In the context of this model, CCRB8 shows a lack of significance and relevance.
However, in its distinct behavioral model, it should be at first retained.

# Evaluation of the formative higher-order constructs
```{r hoc-eval base, echo=FALSE, include=FALSE}
forhocevalbase <- evalmm %>% filter(Mode == "higher-order") %>% rename(HOC = Construct, LOC = Indicator.or.LOC) %>% 
  mutate(Type = NULL, Mode = NULL)
```

## Convergent validity
Convergent validity cannot be evaluated.

## Collinearity
The variance inflation factor (VIF) should be < 5, ideally $\leq$ 3.
```{r hoc-for-eval col, echo = FALSE, include = FALSE}
hocvif <- data.frame(HOC = character(),
                    LOC = character(),
                    VIF = double())
for (i in 1:length(unique(forhocevalbase$HOC))){
  for (j in 1:nrow(filter(forhocevalbase, HOC == unique(forhocevalbase$HOC)[i]))){
    x = unique(forhocevalbase$HOC)[i]
    y = (filter(forhocevalbase, HOC == x))[j,"LOC"]
    hocvif <- hocvif %>% rbind(data.frame(HOC = x,
                              LOC = y,
                              VIF = unlist(summo$validity$vif_items)[paste0({{x}}, ".", {{y}})]))
  }}
```

## Significance and relevance
Indicator weights should be significant (t $\geq$ 1.65, bootstrapping CI does not include 0). Otherwise, the loading  <font face="Symbol">l</font> should be $\geq$ 0.50 and significant. Any positive indicator weight implies relevance.

```{r hoc-for-eval sar, echo=FALSE, include=FALSE}
# Make weights df
bthocwtbase <- rownames_to_column(as.data.frame(sumbomo$bootstrapped_weights)) %>% rename (
  Construct.Rel. = rowname,
  Original.Est.Wt. = "Original Est.",
  Bootstrap.Mean.Wt. = "Bootstrap Mean",
  Bootstrap.SD.Wt. = "Bootstrap SD",
  T.Stat.Wt. = "T Stat.",
  Lower.Bounds.CI.Wt. = "2.5% CI",
  Upper.Bounds.CI.Wt. = "97.5% CI"
)
bthocwtsplit <- base::strsplit(bthocwtbase$Construct.Rel., "  ->  ")
bthocwtsplit1 <- c()
bthocwtsplit2 <- c()
for (i in 1:length(bthocwtsplit)){
  bthocwtsplit1 <- append(bthocwtsplit1, bthocwtsplit[[i]][1])
  bthocwtsplit2 <- append(bthocwtsplit2, bthocwtsplit[[i]][2])
}
bthocwt <- bthocwtbase %>%
  cbind(data.frame(LOC = bthocwtsplit1, HOC = bthocwtsplit2)) %>%
  mutate(Construct.Rel. = NULL,
         Bootstrap.SD.Wt. = NULL,
         '0.in.Wt.CI' = ifelse(Lower.Bounds.CI.Wt. < 0 &  Upper.Bounds.CI.Wt. > 0, TRUE, FALSE),
         Lower.Bounds.CI.Wt. = NULL,
         Upper.Bounds.CI.Wt. = NULL)
# Make loadings df
bthocldbase <- rownames_to_column(as.data.frame(sumbomo$bootstrapped_loadings)) %>% rename(
  Construct.Rel. = rowname,
  Original.Est.Ld. = "Original Est.",
  Bootstrap.Mean.Ld. = "Bootstrap Mean",
  Bootstrap.SD.Ld. = "Bootstrap SD",
  T.Stat.Ld. = "T Stat.",
  Lower.Bounds.CI.Ld. = "2.5% CI",
  Upper.Bounds.CI.Ld. = "97.5% CI"
)
bthocldsplit <- base::strsplit(bthocldbase$Construct.Rel., "  ->  ")
bthocldsplit1 <- c()
bthocldsplit2 <- c()
for (i in 1:length(bthocldsplit)){
  bthocldsplit1 <- append(bthocldsplit1, bthocldsplit[[i]][1])
  bthocldsplit2 <- append(bthocldsplit1, bthocldsplit[[i]][2])
}
bthocld <- btldbase %>%
  cbind(data.frame(LOC = btldsplit1, HOC = btldsplit1)) %>%
  mutate(Construct.Rel. = NULL,
         Bootstrap.SD.Ld. = NULL,
         '0.in.Ld.CI' = ifelse(Lower.Bounds.CI.Ld. < 0 &  Upper.Bounds.CI.Ld. > 0, TRUE, FALSE),
         Lower.Bounds.CI.Ld. = NULL,
         Upper.Bounds.CI.Ld. = NULL)

#Make final data frame
forhocevalmm <- forhocevalbase %>%
  left_join(hocvif[,2:3]) %>%
  left_join(bthocwt[,-5]) %>%
  left_join(bthocld[,-5])
colnames(forhocevalmm)[6] <- paste0("t(", nrow(model$data), ") (weight)")
colnames(forhocevalmm)[10] <- paste0("t(", nrow(model$data), ") (loading)")
```
```{r hoc-for-eval, echo=FALSE}
datatable(forhocevalmm,
          filter = 'top',
          options = list(pageLength = nrow(forhocevalmm)),
          rownames = FALSE,
          colnames = c("Weight (original estimate)" = 4, 
                       "Weight (bootstrap mean)" = 5,
                       "0 in CI (weight)" = 7,
                       "Loading (original estimate)" = 8,
                       "Loading (bootstrap mean)" = 9,
                       "0 in CI (loading)" = 11),
          caption = 'Results of the formative higher-order construct evaluation') %>%
  formatRound(c(3:6, 8:10),
              digits = 3) %>%
  formatStyle('VIF', backgroundColor = styleInterval(cuts = c(3,5), values = c('#00', '#ffe5e5','#ff9999'))) %>%
  formatStyle(colnames(forhocevalmm)[6], backgroundColor = styleInterval(cuts = c(1.65), values = c('#ffe5e5', '#00'))) %>%
  formatStyle('Loading (original estimate)', backgroundColor = styleInterval(cuts = c(0.5), values = c('#ff9999', '#00'))) %>%
  formatStyle('Loading (bootstrap mean)', backgroundColor = styleInterval(cuts = c(0.5), values = c('#ff9999', '#00'))) %>%
  formatStyle(colnames(forhocevalmm)[10], backgroundColor = styleInterval(cuts = c(1.65), values = c('#ff9999', '#00'))) %>%
  formatStyle('0 in CI (weight)', backgroundColor = styleEqual(c(1,0), c('#ffe5e5', '#00'), default = NULL)) %>%
  formatStyle('0 in CI (loading)', backgroundColor = styleEqual(c(1,0), c('#ff9999', '#00'), default = NULL))
```


## Results of the formative higher-order constructs evaluation
For the formative higher-order constructs, there are no issues with collinearity as indicated by the VIF.
The weights of Injunctive Norm and Integrity are not significant, but they can be retained on the basis of a significant and sufficiently large loading.
All other weights are significant and relevant.
The formative higher-order constructs can be retained as hypothesized.

# Results summary
In the reflective measurement model, CCPN2 should be tentatively deleted to rectify internal consistency.
If this leads to problems with discriminant validity reliability, it should be taken back in.
Other than that, the reflective measurement model can be retained as-is.
Because there are incorrigible problems with convergent validity for the Response Belief lower-order constructs and Behavioral Intention, four distinct behavior-specific models should be estimated next.
The formative higher-order constructs can be retained as-is.
